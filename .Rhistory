version
dataset
version
library(tidyverse)
library(tidyverse)
library(tidymoels)
library(tidymodels)
load("namcs08.RData")
dataset = patients %>% mutate(paytype = if_else(paytype == 'Private insurance', 'private_ins', 'non_private_ins'))
dataset
dataset %>% group_by(paytype) %>% summarize(n=n()) %>% mutate(prop = n/sum(n))
dataset = dataset %>% select(-id, -visitreason)
set.seed(1)
split_data = initial_split(dataset, prop=2/3)
training(split_data)
testing(split_data)
my_recipe = recipe(training(split_data), paytype ~ .)
my_recipe
logistic_model = logistic_reg() %>% set_engine('glm') %>% set_mode('classification')
rand_forest_model = rand_forest() %>% set_engine('ranger') %>% set_mode('classification')
logistic_workflow = workflow() %>% add_recipe(my_recipe) %>% add_model(logistic_model)
rand_forest_workflow = workflow() %>% add_recipe(my_recipe) %>% add_model(rand_forest_model)
logistic_results = last_fit(logistic_workflow, split = split_data, metrics = metric_set(roc_auc, pr_auc, accuracy, kap))
logistic_results %>% collect_predictions() %>% glimpse()
logistic_results %>% collect_predictions() %>% glimpse()
logistic_results() %>% collect_metrics()
logistic_results %>% collect_metrics()
glimpse(patients)
load('namcs08.RData')
glimpse(patients)
library(tidymodels)
glimpse(patients)
### Transform paytype to make it binary
dataset =
patient %>%
mutate(paytype = if_else(paytype == 'Private insurance',
'private_ins',
'non_private_ins'))
### Transform paytype to make it binary
dataset =
patients %>%
mutate(paytype = if_else(paytype == 'Private insurance',
'private_ins',
'non_private_ins'))
dataset %>%
group_by(paytype) %>%
summarize(n=n()) %>%
mutate(prop=n/sum(n))
### What did the model predict?
logistic_results %>%
collect_predictions() %>%
glimpse()
### What did the model predict?
logistic_results %>%
collect_predictions() %>%
glimpse()
### Train model
logistic_results =
last_fit(
logistic_workflow,
split = split_data,
metrics = metric_set(roc_auc,
pr_auc,
accuracy,
kap)
)
### What did the model predict?
logistic_results %>%
collect_predictions() %>%
glimpse()
### What did the model predict?
logistic_results %>%
collect_predictions() %>%
glimpse()
### Train model
logistic_results =
last_fit(
logistic_workflow,
split = split_data,
metrics = metric_set(roc_auc,
pr_auc,
accuracy,
kap)
)
# What did the model predict?
logistic_results %>%
collect_predictions() %>%
glimpse()
logistic_results
dataset %>%
group_by(paytype) %>%
summarize(n=n()) %>%
mutate(prop=n/sum(n))
split_data = initial_split(dataset, prop=2/3)
rand_forest_model =
rand_forest() %>%
set_engine('ranger') %>%
set_mode('classification')
rand_forest_workflow =
workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_model)
# Specify recipe with predictors, outcomes & pre-processing steps
my_recipe = recipe(training(split_data), paytype ~ .)
my_recipe
# Pipe into workflow()
logistic_workflow =
workflow() %>%
add_recipe(my_recipe) %>%
add_model(logistic_model)
# Specify model
logistic_model =
logistic_reg() %>%
set_engine('glm') %>%
set_mode('classification')
logistic_workflow =
workflow() %>%
add_recipe(my_recipe) %>%
add_model(logistic_model)
logistic_workflow =
workflow() %>%
add_recipe(my_recipe) %>%
add_model(logistic_model)
logistic_results %>%
collect_predictions() %>%
glimpse()
logistic_results =
last_fit(
logistic_workflow,
split = split_data,
metrics = metric_set(roc_auc,
pr_auc,
accuracy,
kap)
)
.notes
rand_forest_workflow =
workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_model)
logistic_workflow =
workflow() %>%
add_recipe(my_recipe) %>%
add_model(logistic_model)
logistic_model =
logistic_reg() %>%
set_engine('glm') %>%
set_mode('classification')
rand_forest_model =
rand_forest() %>%
set_engine('ranger') %>%
set_mode('classification')
logistic_results =
last_fit(
logistic_workflow,
split = split_data,
metrics = metric_set(roc_auc,
pr_auc,
accuracy,
kap)
)
logistic_results %>%
collect_predictions() %>%
glimpse()
logistic_results %>%
collect_predictions() %>%
glimpse()
dataset
testing(split_data)
logistic_results %>%
collect_predictions() %>%
glimpse()
my_recipe = recipe(training(split_data), paytype ~ .)
logistic_results %>%
collect_predictions() %>%
glimpse()
logistic_results
logistic_results %>%
collect_predictions() %>%
glimpse()
logistic_results %>%
collect_metrics()
logistic_results =
last_fit(
logistic_workflow,
split = split_data,
metrics = metric_set(roc_auc,
pr_auc,
accuracy,
kap)
)
logistic_results %>%
glimpse(.notes)
library
library(tidyverse)
Sys.which("make")
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
Sys.which("make")
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
install.packages("jsonlite", type = "source")
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
restart()
Sys.which("make")
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
pnorm(1)
pnorm(-1.35)
pnorm(-1)
plot(pnorm(1))
pnorm(1)
plot(function(x) pnorm(x, log.p = TRUE), -50, 10,
main = "log { Normal Cumulative }")
pnorm(-1.35, mean=0, sd=1)
pnorm(-1.35, mean=0, sd=3423)
pnorm(-1.35, mean=0, sd=1)
ggplot(pnorm(-1.35, mean=0, sd=1))
plot(pnorm(-1.35, mean=0, sd=1))
x <- seq(5, 15, length=1000)
y <- dnorm(x, mean=10, sd=3)
plot(x, y, type="l", lwd=1)
x <- seq(5, 15, length=1000)
y <- pnorm(x, mean=10, sd=3)
plot(x, y, type="l", lwd=1)
pnorm(-1.35)
1-pnorm(1.48)
pnorm(1.5) - pnorm(-0.4)
pnorm(1.5)
pnorm(-0.4)
pnorm(2) - pnorm(-2)
1 - pnorm(1.089)
1 - pnorm(0.312)
pnorm(1.089, mean=0, sd=1)
pnorm(1.089, mean=5, sd=4)
1 - pnorm(1.089, mean=4313, sd=583)
pnorm(1.089, mean=4313, sd=583)
pnorm(4948, mean=4313, sd=583)
pnorm(4283, mean=4313, sd=583)
pnorm(32, mean=4313, sd=583)
pnorm(432, mean=4313, sd=583)
pnorm(4133, mean=4313, sd=583)
qnorm(0.25)
185 +qnorm(0.25)*42
qnorm(0.25, 185, 42)
qnorm(0.45, 185, 42)
qnorm(0.50, 185, 42)
qnorm(0.61 185, 42)
qnorm(0.61, 185, 42)
qnorm(0.60, 185, 42)
qnorm(0.59, 185, 42)
qnorm(0.60, 185, 42)
qnorm(0.595, 185, 42)
qnorm(0.593, 185, 42)
qnorm(0.594, 185, 42)
qnorm(0.5945, 185, 42)
pnormGC(195, region="above",mean=185, sd=42,graph=TRUE)
library(tigerstats)
require(tigerstats)
install.packages("tigerstats")
library(h2o)
library(h2o)
h2o.init(ip='localhost',
port = 54321,
nthreads= -1,
max_mem_size = '4g')
h2o.init(ip='localhost',
port = 54321,
nthreads= -1,
max_mem_size = '4g')
h2o.init()
h2o.clusterInfo()
airlinesURL = "https://s3.amazonaws.com/h2o-airlinesunpacked/allyears2k.csv"
airlines.hex = h2o.importFile(path = airlinesURL,
destination_frame = "airlines.hex")
summary(airlines.hex)
airlinesURL = "https://s3.amazonaws.com/h2o-airlinesunpacked/allyears2k.csv"
airlines.hex = h2o.importFile(path = airlinesURL,
destination_frame = "airlines.hex")
airlinesURL
airlines.hex = h2o.importFile(path = airlinesURL,
destination_frame = "airlines.hex")
h2o.init()
airlinesURL = "https://s3.amazonaws.com/h2o-airlinesunpacked/allyears2k.csv"
airlines.hex = h2o.importFile(path = airlinesURL,
destination_frame = "airlines.hex")
airlines.hex = h2o.importFile(path = airlinesURL, destination_frame = "airlines.hex")
airlines_path <- "https://s3.amazonaws.com/h2o-airlines-unpacked/allyears2k.csv"
airlines <- h2o.importFile(path = airlines_path)
airlines
summary(airline)
airline <- h2o.importFile(path = airlines_path)
summary(airline)
summary(airline, exact_quantiles=TRUE)
quantile(x = airlines$ArrDelay, na.rm = TRUE)
summary(airline.hex, exact_quantiles=TRUE)
airline.hex <- h2o.importFile(path = airlines_path)
summary(airline.hex, exact_quantiles=TRUE)
h2o.hist(airlines.hex$ArrDelay)
airline.hex <- h2o.importFile(path = airlines_path)
summary(airline.hex, exact_quantiles=TRUE)
quantile(x = airlines$ArrDelay, na.rm = TRUE)
h2o.hist(airlines.hex$ArrDelay)
h2o.init(ip='localhost',
port = 54321,
nthreads= -1,
max_mem_size = '4g')
h2o.init()
airlines_path <- "https://s3.amazonaws.com/h2o-airlines-unpacked/allyears2k.csv"
airline.hex <- h2o.importFile(path = airlines_path)
summary(airline.hex, exact_quantiles=TRUE)
quantile(x = airlines$ArrDelay, na.rm = TRUE)
h2o.hist(airlines.hex$ArrDelay)
airline.hex <- h2o.importFile(path = airlines_path)
airlines.hex <- h2o.importFile(path = airlines_path)
h2o.hist(airlines.hex$ArrDelay)
originFlights = h2o.group_by(data = airlines.hex,
by = "Origin", nrow("Origin"),
gb.control=list(na.methods="rm"))
originFlights
originFlights.R = as.data.frame(originFlights)
originFlights.R
originFlights = h2o.group_by(data = airlines.hex,
by = "Origin", nrow("Origin"),
gb.control=list(na.methods="rm"))
originFlights.R = as.data.frame(originFlights)
originFlights
originFlights.R
tail(originFlights)
which(colnames(airlines.hex)=="Cancelled")
cancellationsByMonth = h2o.group_by(data = airlines.hex,
by = "Month",
sum("Cancelled"),
gb.control= list(na.methods="rm"))
cancellation_rate = cancellationsByMonth$sum_Cancelled/flightsByMonth$nrow
rates_table = h2o.cbind(flightsByMonth$Month,
cancellation_rate)
rates_table.R = as.data.frame(rates_table)
flightsByMonth = h2o.group_by(data = airlines.hex,
by="Month",
nrow("Month"),
gb.control=list(na.methods="rm"))
which(colnames(airlines.hex)=="Cancelled")
cancellationsByMonth = h2o.group_by(data = airlines.hex,
by = "Month",
sum("Cancelled"),
gb.control= list(na.methods="rm"))
cancellation_rate = cancellationsByMonth$sum_Cancelled/flightsByMonth$nrow
rates_table = h2o.cbind(flightsByMonth$Month,
cancellation_rate)
rates_table.R = as.data.frame(rates_table)
rates_table.R
which(colnames(airlines.hex)=="Cancelled")
cancellationsByMonth
flightsByMonth
airlines.hex
airlines.split = h2o.splitFrame(data = airlines.hex,
ratios = 0.85)
airlines.split
airlines.split[1]
airlines.split[[1]]
airlines.split[[2]]
airlines.split[[2]]
airlines.split[[1]]
airlines.split = h2o.splitFrame(data = airlines.hex,
ratios = 0.50)
airlines.split[[1]]
airlines.split[[2]]
Y = "IsDepDelayed"
X = c("Origin", "Dest", "DayofMonth", "Year", "UniqueCarrier", "DayOfWeek", "Month", "DepTime", "ArrTime", "Distance")
airlines.glm <- h2o.glm(training_frame=airlines.train,
x=X, y=Y, family = "binomial", alpha = 0.5)
Y = "IsDepDelayed"
X = c("Origin", "Dest", "DayofMonth", "Year", "UniqueCarrier", "DayOfWeek", "Month", "DepTime", "ArrTime", "Distance")
airlines.glm <- h2o.glm(training_frame=airlines.train,
x=X, y=Y, family = "binomial", alpha = 0.5)
airlines.train = airlines.split[[1]]
31 airlines.test = airlines.split[[2]]
airlines.test = airlines.split[[2]]
airlines.glm <- h2o.glm(training_frame=airlines.train,
x=X, y=Y, family = "binomial", alpha = 0.5)
summary(airlines.glm)
pred = h2o.predict(object = airlines.glm,
newdata = airlines.test)
summary(pred$p1)
pred = h2o.predict(object = airlines.glm,
newdata = airlines.test)
summary(pred$p1)
pred
summary(pred)
pred = h2o.predict(object = airlines.glm,
newdata = airlines.test)
summary(pred)
pred$p1
pred$
;
pred@models
pred$names
pred
airlines.glm
irisPath = system.file("extdata", "iris.csv", package= "h2o")
irisPath
iris.hex = h2o.importFile(path = irisPath, destination_frame = "iris.hex")
iris.hex
iris.hex
h2o.anyFactor()
h2o.anyFactor(iris.hex)
prosPath <- system.file("extdata", "prostate.csv",
package="h2o")
prostate.hex <- h2o.importFile(path = prosPath)
as.factor(prostate.hex[,4])
prostat.hx
prostate.hex
prostate.hex
prostate.hex[,4] <- as.factor(prostate.hex[,4])
as.factor(prostate.hex[,4])
prostate.hex <- h2o.importFile(path = prosPath)
prostate.hex[4]
summary(prostate.hex[,4])
prostate.R <- as.data.frame(prostate.hex)
summary(prostate.R)
prostate.R
prostate.hex
h2o.ls()
prostate.hex
colnames(iris.hex)
iris.hex
iris
colnames(iris)
names(iris)
prostate.qs <- quantile(prostate.hex$PSA, probs=(1:10)/10)
prostate.qs
s = h2o.runif(prostate.hex)
s
summary(s)
s = h2o.runif(prostate)
summary(s)
s
prostate.hex
prostate@models
prostate
prostate.hex
prostate.hex@models
prostate.hex@models
h2o.saveModel(mdl)
mdl
c = rep("Numeric", 11)
c
typeof(c)
c = c("a", "b")
c
typeof(c)
library(shiny)
library(h2o)
source('C:/Users/Yiju Huang/Desktop/splash/demo/demo.R', echo=TRUE)
round(0.12)
round(0.4)
round(0.5)
getwd()
exit()
quit()
View(CO2)
View(swiss)
library(h2o)
h2o.init()
h2o.shutDown()
h2o::h2o.shutdown()
h2o::h2o.init()
h2o::h2o.shutdown()
library(h2o)
source('~/.active-rstudio-document', echo=TRUE)
package.install("h2o")
install.packages("h2o")
install.packages("h2o")
library(h2o)
source('~/.active-rstudio-document', echo=TRUE)
list.files()
getwd()
devtools::install_github("rstudio/crosstalk")
library(devtools)
install.packages("devtools")
devtools::install_github("rstudio/crosstalk")
library(crosstalk)
devtools::install_github("jcheng5/d3scatter")
devtools::install_github("rstudio/leaflet")
library(d3scatter)
d3scatter(iris, ~Petal.Length, ~Petal.Width, ~Species)
shared_iris <- SharedData$new(iris);
d3scatter(shared_iris, ~Petal.Length, ~Petal.Width, ~Species)
library(crosstalk)
shared_iris <- SharedData$new(iris)
bscols(
d3scatter(shared_iris, ~Petal.Length, ~Petal.Width, ~Species, width="100%", height=300),
d3scatter(shared_iris, ~Sepal.Length, ~Sepal.Width, ~Species, width="100%", height=300)
)
Petal
source('~/.active-rstudio-document', echo=TRUE)
library(crosstalk)
shared_iris <- SharedData$new(iris)
bscols(
d3scatter(shared_iris, ~Petal.Length, ~Petal.Width, ~Species, width="100%", height=300),
d3scatter(shared_iris, ~Sepal.Length, ~Sepal.Width, ~Species, width="100%", height=300)
)
Petal
source('~/.active-rstudio-document', echo=TRUE)
mtcars
source('~/karandeep/ct_smp.R', echo=TRUE)
source('~/karandeep/ct_smp.R', echo=TRUE)
list.files()
setwd("karandeep/evpt/")
list.files()
scan(pipe(paste("sed -i '1 s/disp/newvar/' ", filename, sep = "")))
scan(pipe(paste("sed '1 s/disp/newvar/g' gbm_pojo_test.java")))
scan(pipe(paste("sed -i '/^import hex.*/d' gbm_pojo_test.java")))
pipe(paste("sed -i '/^import hex.*/d' gbm_pojo_test.java"))
